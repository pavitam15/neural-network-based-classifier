{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39224983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(888)\n",
    "\n",
    "#from tensorflow import set_random_seed\n",
    "#set_random_seed(4112)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ce49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential       #to define model/ layers\n",
    "from keras.layers import Dense, Activation, Dropout   #to define model/ layers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49113da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# puts data from the csv into a pandas dataframe with headings\n",
    "df = pd.read_csv((r'C:\\Users\\ellio\\OneDrive\\Documents\\ComSci 3rd year\\Computational Intelligence\\wdbc.csv'), names=['id', 'diagnosis', 'f1', 'f2','f3', 'f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30'])\n",
    "# drops the id attribute off all instances in the dataset and stores it\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copy of the dataframe to apply normalisation\n",
    "df_normalised = df.copy()\n",
    "  \n",
    "# Normalize each features to the range of [0, 1]\n",
    "normfeatures = ['f1', 'f2','f3', 'f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']\n",
    "df_normalised[normfeatures] = (df_normalised[normfeatures] - df_normalised[normfeatures].min()) / (df_normalised[normfeatures].max() - df_normalised[normfeatures].min())    \n",
    "   \n",
    "# view normalized data\n",
    "display(df_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce24384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the diagnosis to 1 and 0 for target ouputs of the neural network\n",
    "df_normalised['diagnosis'] = df['diagnosis'].replace(['M','B'],['1','0'], inplace=True )\n",
    "\n",
    "display(df_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the datatype of the target outputs to int64\n",
    "df_normalised['diagnosis'] = pd.to_numeric(df['diagnosis'])\n",
    "\n",
    "display(df_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c53a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from random 70% of normalised set for the training set\n",
    "training_set = df_normalised.sample(frac = 0.70)\n",
    " \n",
    "# create a dataframe from the left over 30% for the testing set\n",
    "testing_set = df_normalised.drop(training_set.index)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training set arrays\n",
    "training_outputs = training_set[['diagnosis']].to_numpy()\n",
    "training_outputs = training_outputs.astype('float64')\n",
    "training_inputs = training_set[['f1', 'f2','f3', 'f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the testing set arrays\n",
    "testing_inputs = testing_set[['f1', 'f2','f3', 'f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']].to_numpy()\n",
    "\n",
    "testing_outputs = testing_set[['diagnosis']].to_numpy()\n",
    "testing_outputs = testing_outputs.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n",
    "model_3.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_3.add(Dense(15, activation='relu'))\n",
    "model_3.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model_2.fit(training_inputs, training_outputs, batch_size=199, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc52b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.title('\"MODEL2\":  Loss ')\n",
    "\n",
    "\n",
    "    \n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.title('\"MODEL2\":  Accuracy ')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.plot(history2.history['mean_squared_error'])\n",
    "plt.title('\"MODEL 1\":   Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model_2.predict(testing_inputs), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4827523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_outputs,predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363930e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(testing_outputs,predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
